{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/uscensusbureau/acs-summary-file/wiki/Python-Table-Data-for-All-Tracts\n",
    "\n",
    "According to the [data explorer notes](https://data.census.gov/table/ACSDT5Y2020.B16001?q=B16001:%20Language%20Spoken%20at%20Home%20by%20Ability%20to%20Speak%20English%20for%20the%20Population%205%20Years%20and%20Over), Public Use Microdata Sample Areas (PUMAs) (795) are the most precise available version of this dataset (for privacy reasons). More info about PUMAs [here](https://www.census.gov/programs-surveys/geography/guidance/geo-areas/pumas.htm). Less so are congressional districts (500), but seem easier to work with, so I'll start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftplib import FTP\n",
    "import os, sys\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import lonboard\n",
    "from lonboard import viz, Map, ScatterplotLayer, SolidPolygonLayer\n",
    "from lonboard.colormap import apply_categorical_cmap, DiscreteColormap\n",
    "# from palettable.colorbrewer.diverging import BrBG_10\n",
    "from lonboard.layer_extension import CollisionFilterExtension\n",
    "from lonboard.layer_extension import DataFilterExtension\n",
    "\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "# from shapely.ops import unary_union\n",
    "# from shapely import wkt\n",
    "import random\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_for_sumlevel(tblid, year, dataset, sumlevel):\n",
    "\n",
    "    #create output directory. \n",
    "    outdir = 'survey_data2'\n",
    "    try:\n",
    "        os.mkdir(outdir)\n",
    "    except FileExistsError as e:\n",
    "        print(f\"directory named '{outdir}' already exists. delete it and try again.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    dir =f\"/programs-surveys/acs/summary_file/{year}/prototype/{dataset}YRData/\"\n",
    "\n",
    "    #go to ftp site\n",
    "    ftp = FTP(\"ftp2.census.gov\")\n",
    "    ftp.login(\"\",\"\")\n",
    "    ftp.cwd(dir)\n",
    "\n",
    "    #get .dat file based on tblid or all tables\n",
    "    files = [x for x in ftp.nlst() if f\"{tblid}.dat\" in x or (tblid==\"*\" and \".dat\" in x)]\n",
    "\n",
    "    for file in files:\n",
    "        #read data file and query for summary level (http faster than ftp)\n",
    "        df = pd.read_csv(f\"https://www2.census.gov{dir}{file}\", sep=\"|\")\n",
    "        df = df[ df['GEO_ID'].str.startswith(sumlevel) ]\n",
    "\n",
    "        #output\n",
    "        if not df.empty:\n",
    "            df.to_csv(f\"{outdir}/{file}\", sep=\"|\", index=False)\n",
    "            print(f\"{outdir}/{file} output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Summary level definitions](https://mcdc.missouri.edu/geography/sumlevs/#:~:text=the%20U.S.-,Summary%20Levels,-All%20MCDC%20census)\n",
    "\n",
    "Congress districts (500) (cd116) are less precise than the most precise version of languages spoken at home, which are PUMAs (795). However, I couldn't get the PUMA shapefiles to align perfectly with the PUMA-level languages spoken at home dataset (b16001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey_data2/acsdt5y2020-c16001.dat output.\n"
     ]
    }
   ],
   "source": [
    "#MARKDOWN CELL\n",
    "\n",
    "#get one table for tracts (140)\n",
    "\n",
    "table_for_sumlevel(tblid = 'c16001', year=2020, dataset=5, sumlevel='140')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to re-do this workflow and instead of saving a .dat to an output directory and re-loading it, I can directly load it as a df\n",
    "\n",
    "`GEO_ID` [explanation ](https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html#:~:text=The%20%E2%80%9CGEO.ID%E2%80%9D%20field%20contains%2014%2Ddigit%20codes%20that%20identify%20the%20summary%20level%20of%20data%2C%20the%20geographic%20component%20of%20the%20data%20and%20FIPS%20codes%20that%20uniquely%20identify%20the%20data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('survey_data/acsdt5y2020-c16001.dat', delimiter='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table header labels [here](https://www2.census.gov/programs-surveys/acs/summary_file/2020/prototype/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take last 11 digits of GEO_ID to make new column that matches the shapefile parameter \n",
    "df['GEO_ID_SHORT'] = df.GEO_ID.str[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some initial calculations and add them as new columns\n",
    "df['ONLY_ENG_PER'] = df.C16001_E002 / df.C16001_E001\n",
    "# df['SPANISH_PER'] = df.B16001_E003 / df.B16001_E001\n",
    "# df['FRENCH_PER'] = df.B16001_E006 / df.B16001_E001\n",
    "# df['ITALIAN_PER'] = df.B16001_E012 / df.B16001_E001\n",
    "# df['PORTUGUESE_PER'] = df.B16001_E015 / df.B16001_E001\n",
    "# df['CHINESE_PER'] = df.B16001_E075 / df.B16001_E001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue with default encoding, so I'm \"replacing\" the text with issues (see https://docs.python.org/3/library/codecs.html#error-handlers)\n",
    "df2 = pd.read_csv('ACS2020_Table_Shells.csv', encoding_errors=\"replace\")\n",
    "labels = df2[df2['Table ID'] == 'C16001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/q66l1j8d7k3d1543fzt8qwfh0000gn/T/ipykernel_51019/955727189.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_labels['lang_code'] = selected_labels['Unique ID'].apply(lambda x: x.replace('_', '_E'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table ID</th>\n",
       "      <th>Line</th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Stub</th>\n",
       "      <th>Data Release</th>\n",
       "      <th>lang_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>C16001</td>\n",
       "      <td>2</td>\n",
       "      <td>C16001_002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12605</th>\n",
       "      <td>C16001</td>\n",
       "      <td>3</td>\n",
       "      <td>C16001_003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>C16001</td>\n",
       "      <td>6</td>\n",
       "      <td>C16001_006</td>\n",
       "      <td>French, Haitian, or Cajun:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>C16001</td>\n",
       "      <td>9</td>\n",
       "      <td>C16001_009</td>\n",
       "      <td>German or other West Germanic languages:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12614</th>\n",
       "      <td>C16001</td>\n",
       "      <td>12</td>\n",
       "      <td>C16001_012</td>\n",
       "      <td>Russian, Polish, or other Slavic languages:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12617</th>\n",
       "      <td>C16001</td>\n",
       "      <td>15</td>\n",
       "      <td>C16001_015</td>\n",
       "      <td>Other Indo-European languages:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>C16001</td>\n",
       "      <td>18</td>\n",
       "      <td>C16001_018</td>\n",
       "      <td>Korean:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12623</th>\n",
       "      <td>C16001</td>\n",
       "      <td>21</td>\n",
       "      <td>C16001_021</td>\n",
       "      <td>Chinese (incl. Mandarin, Cantonese):</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12626</th>\n",
       "      <td>C16001</td>\n",
       "      <td>24</td>\n",
       "      <td>C16001_024</td>\n",
       "      <td>Vietnamese:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12629</th>\n",
       "      <td>C16001</td>\n",
       "      <td>27</td>\n",
       "      <td>C16001_027</td>\n",
       "      <td>Tagalog (incl. Filipino):</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12632</th>\n",
       "      <td>C16001</td>\n",
       "      <td>30</td>\n",
       "      <td>C16001_030</td>\n",
       "      <td>Other Asian and Pacific Island languages:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12635</th>\n",
       "      <td>C16001</td>\n",
       "      <td>33</td>\n",
       "      <td>C16001_033</td>\n",
       "      <td>Arabic:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12638</th>\n",
       "      <td>C16001</td>\n",
       "      <td>36</td>\n",
       "      <td>C16001_036</td>\n",
       "      <td>Other and unspecified languages:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C16001_E036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Table ID Line   Unique ID                                         Stub  \\\n",
       "12604   C16001    2  C16001_002                           Speak only English   \n",
       "12605   C16001    3  C16001_003                                     Spanish:   \n",
       "12608   C16001    6  C16001_006                   French, Haitian, or Cajun:   \n",
       "12611   C16001    9  C16001_009     German or other West Germanic languages:   \n",
       "12614   C16001   12  C16001_012  Russian, Polish, or other Slavic languages:   \n",
       "12617   C16001   15  C16001_015               Other Indo-European languages:   \n",
       "12620   C16001   18  C16001_018                                      Korean:   \n",
       "12623   C16001   21  C16001_021         Chinese (incl. Mandarin, Cantonese):   \n",
       "12626   C16001   24  C16001_024                                  Vietnamese:   \n",
       "12629   C16001   27  C16001_027                    Tagalog (incl. Filipino):   \n",
       "12632   C16001   30  C16001_030    Other Asian and Pacific Island languages:   \n",
       "12635   C16001   33  C16001_033                                      Arabic:   \n",
       "12638   C16001   36  C16001_036             Other and unspecified languages:   \n",
       "\n",
       "      Data Release    lang_code  \n",
       "12604          NaN  C16001_E002  \n",
       "12605          NaN  C16001_E003  \n",
       "12608          NaN  C16001_E006  \n",
       "12611          NaN  C16001_E009  \n",
       "12614          NaN  C16001_E012  \n",
       "12617          NaN  C16001_E015  \n",
       "12620          NaN  C16001_E018  \n",
       "12623          NaN  C16001_E021  \n",
       "12626          NaN  C16001_E024  \n",
       "12629          NaN  C16001_E027  \n",
       "12632          NaN  C16001_E030  \n",
       "12635          NaN  C16001_E033  \n",
       "12638          NaN  C16001_E036  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the \"language\" rows, including the total\n",
    "\n",
    "# add 2 for all people, 3 for only english speakers\n",
    "initial_rows = [3, 4]\n",
    "\n",
    "# Every 3rd row starting from row 8 (index 7)\n",
    "# Calculate the end of the range to be the number of rows in the DataFrame\n",
    "every_third_row = range(7, len(labels), 3)\n",
    "\n",
    "# Combine the lists of indices\n",
    "selected_indices = initial_rows + list(every_third_row)\n",
    "\n",
    "# Use iloc to select the rows\n",
    "selected_labels = labels.iloc[selected_indices]\n",
    "\n",
    "# Add the letter \"E\" to make labels and dataset language codes match\n",
    "selected_labels['lang_code'] = selected_labels['Unique ID'].apply(lambda x: x.replace('_', '_E'))\n",
    "\n",
    "# Display the selected rows\n",
    "selected_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the language codes as a list, for processing later\n",
    "all_lang = selected_labels['lang_code'].values.tolist()\n",
    "\n",
    "# And all language codes + names as a dictionary\n",
    "all_lang_dict = dict(zip(selected_labels.lang_code, selected_labels.Stub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes a \"deep copy\" instead of a shallow copy, which was changing all_lang. More info: https://stackoverflow.com/questions/62080370/my-original-list-is-changing-when-using-append-or-extend\n",
    "keep_col = all_lang[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns that are needed. Make list with all lang column names, add a few extra important ones\n",
    "keep_col.extend(['GEO_ID', 'GEO_ID_SHORT', 'ONLY_ENG_PER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>C16001_E002</th>\n",
       "      <th>C16001_E003</th>\n",
       "      <th>C16001_E006</th>\n",
       "      <th>C16001_E009</th>\n",
       "      <th>C16001_E012</th>\n",
       "      <th>C16001_E015</th>\n",
       "      <th>C16001_E018</th>\n",
       "      <th>C16001_E021</th>\n",
       "      <th>C16001_E024</th>\n",
       "      <th>C16001_E027</th>\n",
       "      <th>C16001_E030</th>\n",
       "      <th>C16001_E033</th>\n",
       "      <th>C16001_E036</th>\n",
       "      <th>GEO_ID_SHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400000US01001020100</td>\n",
       "      <td>1829</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US01001020200</td>\n",
       "      <td>1640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US01001020300</td>\n",
       "      <td>3304</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01001020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US01001020400</td>\n",
       "      <td>3227</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>01001020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US01001020501</td>\n",
       "      <td>3591</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01001020501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85390</th>\n",
       "      <td>1400000US72153750501</td>\n",
       "      <td>489</td>\n",
       "      <td>4448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72153750501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85391</th>\n",
       "      <td>1400000US72153750502</td>\n",
       "      <td>212</td>\n",
       "      <td>2385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72153750502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85392</th>\n",
       "      <td>1400000US72153750503</td>\n",
       "      <td>152</td>\n",
       "      <td>1822</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72153750503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85393</th>\n",
       "      <td>1400000US72153750601</td>\n",
       "      <td>395</td>\n",
       "      <td>3922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72153750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85394</th>\n",
       "      <td>1400000US72153750602</td>\n",
       "      <td>108</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85395 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GEO_ID  C16001_E002  C16001_E003  C16001_E006  \\\n",
       "0      1400000US01001020100         1829            5            5   \n",
       "1      1400000US01001020200         1640            0            0   \n",
       "2      1400000US01001020300         3304          221            0   \n",
       "3      1400000US01001020400         3227           18            0   \n",
       "4      1400000US01001020501         3591           56            0   \n",
       "...                     ...          ...          ...          ...   \n",
       "85390  1400000US72153750501          489         4448            0   \n",
       "85391  1400000US72153750502          212         2385            0   \n",
       "85392  1400000US72153750503          152         1822           18   \n",
       "85393  1400000US72153750601          395         3922            0   \n",
       "85394  1400000US72153750602          108         2024            0   \n",
       "\n",
       "       C16001_E009  C16001_E012  C16001_E015  C16001_E018  C16001_E021  \\\n",
       "0                0            0            0            0            0   \n",
       "1               11            0            0            0            0   \n",
       "2                0           17            0            0            0   \n",
       "3                0            2            0            0            0   \n",
       "4                0          184            1            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "85390            0            0            0            0            0   \n",
       "85391            0            0            0            0            0   \n",
       "85392            0            0            0            0            0   \n",
       "85393            0            0            0            0            0   \n",
       "85394            0            0            0            0            0   \n",
       "\n",
       "       C16001_E024  C16001_E027  C16001_E030  C16001_E033  C16001_E036  \\\n",
       "0                0            4            0            0            0   \n",
       "1                0            0            0            0            0   \n",
       "2               18           13           13            0            0   \n",
       "3                0            0           17            0          145   \n",
       "4                0           28           52            0            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "85390            0            0            0            0            0   \n",
       "85391            0            0            0            0            0   \n",
       "85392            0            0            0            0            0   \n",
       "85393            0            0            0            0            0   \n",
       "85394            0            0            0            0            0   \n",
       "\n",
       "      GEO_ID_SHORT  \n",
       "0      01001020100  \n",
       "1      01001020200  \n",
       "2      01001020300  \n",
       "3      01001020400  \n",
       "4      01001020501  \n",
       "...            ...  \n",
       "85390  72153750501  \n",
       "85391  72153750502  \n",
       "85392  72153750503  \n",
       "85393  72153750601  \n",
       "85394  72153750602  \n",
       "\n",
       "[85395 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.columns.intersection(keep_col)]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add [2020 shapefiles](https://www.census.gov/geographies/mapping-files/time-series/geo/cartographic-boundary.2020.html#list-tab-1883739534) at 5m resolution (for census tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census tracts\n",
    "shp = gpd.read_file('geos/cb_2020_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>C16001_E002</th>\n",
       "      <th>C16001_E003</th>\n",
       "      <th>C16001_E006</th>\n",
       "      <th>C16001_E009</th>\n",
       "      <th>C16001_E012</th>\n",
       "      <th>C16001_E015</th>\n",
       "      <th>C16001_E018</th>\n",
       "      <th>C16001_E021</th>\n",
       "      <th>C16001_E024</th>\n",
       "      <th>...</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>NAMELSAD</th>\n",
       "      <th>STUSPS</th>\n",
       "      <th>NAMELSADCO</th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>LSAD</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400000US01001020100</td>\n",
       "      <td>1829</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>201</td>\n",
       "      <td>Census Tract 201</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>CT</td>\n",
       "      <td>9825304</td>\n",
       "      <td>28435</td>\n",
       "      <td>POLYGON ((-86.50910 32.47349, -86.50577 32.475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400000US01001020200</td>\n",
       "      <td>1640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>202</td>\n",
       "      <td>Census Tract 202</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>CT</td>\n",
       "      <td>3320818</td>\n",
       "      <td>5669</td>\n",
       "      <td>POLYGON ((-86.48093 32.48154, -86.47945 32.485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1400000US01001020300</td>\n",
       "      <td>3304</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>203</td>\n",
       "      <td>Census Tract 203</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>CT</td>\n",
       "      <td>5349271</td>\n",
       "      <td>9054</td>\n",
       "      <td>POLYGON ((-86.47087 32.47573, -86.46964 32.478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400000US01001020400</td>\n",
       "      <td>3227</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>204</td>\n",
       "      <td>Census Tract 204</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>CT</td>\n",
       "      <td>6384282</td>\n",
       "      <td>8408</td>\n",
       "      <td>POLYGON ((-86.45394 32.49318, -86.45308 32.493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400000US01001020501</td>\n",
       "      <td>3591</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>205.01</td>\n",
       "      <td>Census Tract 205.01</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>CT</td>\n",
       "      <td>6203654</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-86.43826 32.45293, -86.43640 32.455...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GEO_ID  C16001_E002  C16001_E003  C16001_E006  C16001_E009  \\\n",
       "0  1400000US01001020100         1829            5            5            0   \n",
       "1  1400000US01001020200         1640            0            0           11   \n",
       "2  1400000US01001020300         3304          221            0            0   \n",
       "3  1400000US01001020400         3227           18            0            0   \n",
       "4  1400000US01001020501         3591           56            0            0   \n",
       "\n",
       "   C16001_E012  C16001_E015  C16001_E018  C16001_E021  C16001_E024  ...  \\\n",
       "0            0            0            0            0            0  ...   \n",
       "1            0            0            0            0            0  ...   \n",
       "2           17            0            0            0           18  ...   \n",
       "3            2            0            0            0            0  ...   \n",
       "4          184            1            0            0            0  ...   \n",
       "\n",
       "         GEOID    NAME             NAMELSAD  STUSPS      NAMELSADCO  \\\n",
       "0  01001020100     201     Census Tract 201      AL  Autauga County   \n",
       "1  01001020200     202     Census Tract 202      AL  Autauga County   \n",
       "2  01001020300     203     Census Tract 203      AL  Autauga County   \n",
       "3  01001020400     204     Census Tract 204      AL  Autauga County   \n",
       "4  01001020501  205.01  Census Tract 205.01      AL  Autauga County   \n",
       "\n",
       "  STATE_NAME LSAD    ALAND AWATER  \\\n",
       "0    Alabama   CT  9825304  28435   \n",
       "1    Alabama   CT  3320818   5669   \n",
       "2    Alabama   CT  5349271   9054   \n",
       "3    Alabama   CT  6384282   8408   \n",
       "4    Alabama   CT  6203654      0   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-86.50910 32.47349, -86.50577 32.475...  \n",
       "1  POLYGON ((-86.48093 32.48154, -86.47945 32.485...  \n",
       "2  POLYGON ((-86.47087 32.47573, -86.46964 32.478...  \n",
       "3  POLYGON ((-86.45394 32.49318, -86.45308 32.493...  \n",
       "4  POLYGON ((-86.43826 32.45293, -86.43640 32.455...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge geographic file and survey data, turn it into a GeoDataFrame\n",
    "joined = gpd.GeoDataFrame(pd.merge(df, shp, how=\"inner\" , left_on='GEO_ID_SHORT', right_on='GEOID'))\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled points\n",
    "\n",
    "https://geopandas.org/en/stable/docs/user_guide/sampling.html\n",
    "\n",
    "https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.sample_points.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach, from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_points(poly, num_points):\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    points = []\n",
    "\n",
    "    while len(points) < num_points:\n",
    "        random_point = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if random_point.within(poly):\n",
    "            points.append(random_point)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign random colors (x, y, z) to each language\n",
    "language_color_map = {language: [random.randint(0, 255) for _ in range(3)] for language in all_lang}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR hardcode colormap\n",
    "language_color_map = {\n",
    "  'C16001_E002': [141, 211, 199, 200],\n",
    "  'C16001_E003': [255, 255, 179, 200],\n",
    "  'C16001_E006': [190, 186, 218, 200],\n",
    "  'C16001_E009': [251, 128, 114, 200],\n",
    "  'C16001_E012': [128, 177, 211, 200],\n",
    "  'C16001_E015': [253, 180, 98, 200],\n",
    "  'C16001_E018': [179, 222, 105, 200],\n",
    "  'C16001_E021': [252, 205, 229, 200],\n",
    "  'C16001_E024': [217, 217, 217, 200],\n",
    "  'C16001_E027': [188, 128, 189, 200],\n",
    "  'C16001_E030': [204, 235, 197, 200],\n",
    "  'C16001_E033': [255, 237, 111, 200],\n",
    "  'C16001_E036': [255, 255, 255, 200],\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list = []\n",
    "for index, row in gdf.iterrows():\n",
    "    poly = row['geometry']\n",
    "    for lang in all_lang:\n",
    "        num_speakers = row[lang]\n",
    "        num_points = num_speakers // 750  # Assuming one dot represents X speakers\n",
    "        points = generate_random_points(poly, num_points)\n",
    "        for point in points:\n",
    "            points_list.append({'geometry': point, 'language': lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the position of each language code in all_lang_dict as values\n",
    "lang_code_to_index = {code: i for i, code in enumerate(sorted(all_lang_dict.keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not quite sure what this does...\n",
    "points_gdf = gpd.GeoDataFrame(points_list, crs=gdf.crs)\n",
    "\n",
    "# Add a new column, language_name, to the geodataframe based on the key in the language column and the value from the all_lang_dict dictionary\n",
    "points_gdf['language_name'] = points_gdf['language'].map(all_lang_dict)\n",
    "\n",
    "# Add position in all_lang_dict as row\n",
    "points_gdf['language_index'] = points_gdf['language'].map(lang_code_to_index)\n",
    "\n",
    "# points_gdf.to_file('export/data_750.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>language</th>\n",
       "      <th>language_name</th>\n",
       "      <th>language_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-86.47700 32.46688)</td>\n",
       "      <td>C16001_E002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (-86.48152 32.48594)</td>\n",
       "      <td>C16001_E002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (-86.47657 32.47003)</td>\n",
       "      <td>C16001_E002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (-86.47843 32.48397)</td>\n",
       "      <td>C16001_E002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (-86.46697 32.46448)</td>\n",
       "      <td>C16001_E002</td>\n",
       "      <td>Speak only English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318892</th>\n",
       "      <td>POINT (-66.85496 18.01466)</td>\n",
       "      <td>C16001_E003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318893</th>\n",
       "      <td>POINT (-66.82775 18.00243)</td>\n",
       "      <td>C16001_E003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318894</th>\n",
       "      <td>POINT (-66.82129 18.02987)</td>\n",
       "      <td>C16001_E003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318895</th>\n",
       "      <td>POINT (-66.84811 18.00320)</td>\n",
       "      <td>C16001_E003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318896</th>\n",
       "      <td>POINT (-66.85901 17.99138)</td>\n",
       "      <td>C16001_E003</td>\n",
       "      <td>Spanish:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318897 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          geometry     language       language_name  \\\n",
       "0       POINT (-86.47700 32.46688)  C16001_E002  Speak only English   \n",
       "1       POINT (-86.48152 32.48594)  C16001_E002  Speak only English   \n",
       "2       POINT (-86.47657 32.47003)  C16001_E002  Speak only English   \n",
       "3       POINT (-86.47843 32.48397)  C16001_E002  Speak only English   \n",
       "4       POINT (-86.46697 32.46448)  C16001_E002  Speak only English   \n",
       "...                            ...          ...                 ...   \n",
       "318892  POINT (-66.85496 18.01466)  C16001_E003            Spanish:   \n",
       "318893  POINT (-66.82775 18.00243)  C16001_E003            Spanish:   \n",
       "318894  POINT (-66.82129 18.02987)  C16001_E003            Spanish:   \n",
       "318895  POINT (-66.84811 18.00320)  C16001_E003            Spanish:   \n",
       "318896  POINT (-66.85901 17.99138)  C16001_E003            Spanish:   \n",
       "\n",
       "        language_index  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "318892               1  \n",
       "318893               1  \n",
       "318894               1  \n",
       "318895               1  \n",
       "318896               1  \n",
       "\n",
       "[318897 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# makes sure that the lanugage column values are strings, to match language_color_map\n",
    "points_gdf.astype({'language':'string', 'language_name':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = DataFilterExtension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/.pyenv/versions/3.8.12/lib/python3.8/site-packages/lonboard/_geoarrow/ops/reproject.py:78: UserWarning: Input being reprojected to EPSG:4326 CRS\n",
      "  warnings.warn(\"Input being reprojected to EPSG:4326 CRS\")\n",
      "/Users/will/.pyenv/versions/3.8.12/lib/python3.8/site-packages/lonboard/_geoarrow/ops/reproject.py:78: UserWarning: Input being reprojected to EPSG:4326 CRS\n",
      "  warnings.warn(\"Input being reprojected to EPSG:4326 CRS\")\n"
     ]
    }
   ],
   "source": [
    "layer = ScatterplotLayer.from_geopandas(\n",
    "    gdf = points_gdf,\n",
    "    extensions=[extension],\n",
    "    get_filter_value=points_gdf['language_index'],\n",
    "    filter_range = [min(lang_code_to_index.values()), max(lang_code_to_index.values())],\n",
    "    get_fill_color = apply_categorical_cmap(points_gdf.language, language_color_map),\n",
    "    radius_scale = 50,\n",
    "    opacity = 1,\n",
    "    billboard = True,\n",
    "    auto_downcast = True,\n",
    "    )\n",
    "\n",
    "layer2 = SolidPolygonLayer.from_geopandas(\n",
    "    gdf = shp,\n",
    "    get_fill_color = [255,186,3],\n",
    "    auto_highlight = True,\n",
    ")\n",
    "\n",
    "m = Map(\n",
    "    layers=[layer2, layer],\n",
    "    _height=800,\n",
    "    basemap_style = lonboard.basemap.CartoBasemap.DarkMatter\n",
    "    )\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc979cb0f604589b2224b2b410a3c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.0, 12.0), description='Slider: ', max=12.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FloatRangeSlider\n",
    "\n",
    "slider = FloatRangeSlider(\n",
    "    value=(0, 12),\n",
    "    min=0,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description=\"Slider: \"\n",
    ")\n",
    "slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ipywidgets.jsdlink(\n",
    "    (slider, \"value\"),\n",
    "    (layer, \"filter_range\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test getting 1 language per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = points_gdf[points_gdf['language'] == \"C16001_E002\"]\n",
    "english_color = language_color_map['C16001_E002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = points_gdf[points_gdf['language'] == \"C16001_E003\"]\n",
    "spanish_color = language_color_map['C16001_E003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/.pyenv/versions/3.8.12/lib/python3.8/site-packages/lonboard/_geoarrow/ops/reproject.py:78: UserWarning: Input being reprojected to EPSG:4326 CRS\n",
      "  warnings.warn(\"Input being reprojected to EPSG:4326 CRS\")\n",
      "/Users/will/.pyenv/versions/3.8.12/lib/python3.8/site-packages/lonboard/_geoarrow/ops/reproject.py:78: UserWarning: Input being reprojected to EPSG:4326 CRS\n",
      "  warnings.warn(\"Input being reprojected to EPSG:4326 CRS\")\n"
     ]
    }
   ],
   "source": [
    "english_layer = ScatterplotLayer.from_geopandas(\n",
    "    english,\n",
    "    get_fill_color = english_color,\n",
    "    radius_scale = 50,\n",
    "    opacity = 1,\n",
    "    billboard = True,\n",
    "    auto_downcast = True,\n",
    "    )\n",
    "\n",
    "spanish_layer = ScatterplotLayer.from_geopandas(\n",
    "    spanish,\n",
    "    get_fill_color = spanish_color,\n",
    "    radius_scale = 50,\n",
    "    opacity = 1,\n",
    "    billboard = True,\n",
    "    auto_downcast = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Map(\n",
    "    layers=[english_layer, spanish_layer],\n",
    "    _height=600,\n",
    "    basemap_style = lonboard.basemap.CartoBasemap.DarkMatter\n",
    "    )\n",
    "\n",
    "m2.to_html('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
